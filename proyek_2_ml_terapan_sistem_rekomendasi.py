# -*- coding: utf-8 -*-
"""Proyek 2_ML Terapan_Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D8JcCuibRCvsyY1VNX9crEcg5VyZIv13

**Proyek Kedua_Sistem Rekomendasi**

Nama: Aisyah Amelia Zarah Juaita

Cohort ID: MC189D5X0464

Proyek Machine Learning: Travel Recommendation System

Sumber Data: kaggle

# 1. Data Understanding
"""

!pip install tensorflow

"""## Import Library yang Dibutuhkan"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

# Load dataset
tourism_rating = pd.read_csv("/content/tourism_rating.csv")
tourism = pd.read_csv("/content/tourism_with_id.csv")
user = pd.read_csv("/content/user.csv")

"""Pada tahap ini, dilakukan pemuatan tiga dataset utama yang akan digunakan dalam sistem rekomendasi tempat wisata. Dataset `tourism_rating.csv` memuat data penilaian atau rating yang diberikan pengguna terhadap berbagai destinasi wisata, mencerminkan interaksi antara pengguna dan tempat wisata. Dataset `tourism_with_id.csv` berisi informasi detail mengenai destinasi wisata, termasuk ID tempat, nama, dan atribut tambahan seperti kategori. Sementara itu, dataset `user.csv` berisi data pengguna yang memberikan rating, yang kemungkinan mencakup informasi seperti ID pengguna dan atribut demografis lainnya. Ketiga dataset ini akan digabungkan dan diproses lebih lanjut untuk membangun model rekomendasi berbasis content-based dan collaborative filtering.

## Univariate Exploratory Data Analysis

1. tourism_rating:

    1. `User_Id` - ID unik yang merepresentasikan pengguna yang memberi rating.
    2. `Place_Id``- ID unik untuk setiap tempat wisata yang diberi rating.
    3. `Place_Ratings` - Nilai rating (penilaian) yang diberikan user terhadap tempat wisata tersebut (biasanya skala 1-5).

2. tourism:
    1. `Place_Id` - ID unik tempat wisata (digunakan sebagai kunci relasi).
    2. `Place_Name` - Nama tempat wisata.
    3. `Description` - Deskripsi singkat tempat wisata.
    4. `Category` - Kategori tempat wisata.
    5. `City` - Kota tempat wisata berada.
    6. `Price` - Estimasi harga tiket masuk atau biaya kunjungan.
    7. `Rating` - Rating umum atau popularitas tempat.
    8. `Time_Minutes` - Estimasi waktu kunjungan dalam menit (durasi).
    9. `Coordinate` - Lokasi geografis gabungan (lat-long dalam satu string).
    10. `Lat` - Latitude tempat wisata (lintang).
    11. `Long` - Longitude tempat wisata (bujur).
    12. `Unnamed: 11` - Kolom kosong.
    13. `Unnamed: 12` - Kolom kosong.

3. user:

    1. `User_Id` - ID unik pengguna.
    2. `Location` - 	Lokasi pengguna (bisa berupa kota, provinsi, atau nama tempat tinggal).
    3. `Age` - 	Umur pengguna.
"""

tourism_rating.head()

"""Dataset tourism_rating berisi data interaksi antara pengguna dan tempat wisata dalam bentuk rating. Setiap baris merepresentasikan satu penilaian yang diberikan oleh pengguna (User_Id) terhadap suatu destinasi wisata (Place_Id) dengan skor tertentu pada kolom Place_Ratings."""

tourism_rating.info()

"""Hasil dari tourism_rating.info() menunjukkan bahwa dataset terdiri dari 10.000 baris dan 3 kolom: User_Id, Place_Id, dan Place_Ratings. Semua kolom bertipe data int64 dan tidak memiliki missing value (nilai kosong). Ini berarti data bersih dan siap digunakan untuk analisis atau pelatihan model rekomendasi tanpa perlu proses imputasi atau pembersihan tambahan."""

tourism.head()

"""Dataset `tourism` berisi informasi detail tentang destinasi wisata. Setiap baris merepresentasikan satu tempat wisata, dengan kolom-kolom seperti `Place_Id` (ID tempat), `Place_Name` (nama tempat), `Description` (deskripsi), `Category` (jenis wisata), `City` (kota), `Price` (harga tiket), `Rating` (nilai rating umum), `Time_Minutes` (perkiraan durasi kunjungan), serta koordinat geografis (`Lat` dan `Long`). Terdapat juga kolom `Coordinate` dalam format dictionary, dan dua kolom tambahan (`Unnamed: 11` dan `Unnamed: 12`) yang tampaknya tidak terpakai atau hasil dari proses ekspor. Data ini penting untuk sistem rekomendasi berbasis konten karena menyediakan fitur-fitur yang bisa digunakan untuk mengukur kemiripan antar tempat wisata.

"""

tourism.info()

"""Hasil `tourism.info()` menunjukkan bahwa dataset memiliki 437 entri dan 13 kolom. Sebagian besar kolom terisi penuh, kecuali `Time_Minutes` yang hanya memiliki 205 nilai (mengandung banyak missing value) dan `Unnamed: 11` yang seluruhnya kosong. Kolom seperti `Place_Id`, `Place_Name`, `Description`, `Category`, dan `City` menyimpan informasi utama tentang tempat wisata, sedangkan `Price`, `Rating`, `Lat`, dan `Long` memberikan data numerik terkait lokasi dan preferensi. Kolom `Unnamed: 11` sebaiknya dihapus karena tidak mengandung informasi. Dataset ini cocok digunakan untuk analisis konten destinasi wisata dan visualisasi lokasi.

"""

user.head()

"""Dataset `user` berisi informasi tentang pengguna yang memberikan rating pada tempat wisata. Setiap baris mencakup `User_Id` (ID unik pengguna), `Location` (asal kota dan provinsi), serta `Age` (usia pengguna). Data ini berguna untuk analisis demografis dan dapat dimanfaatkan dalam sistem rekomendasi berbasis pengguna (collaborative filtering) atau untuk personalisasi rekomendasi berdasarkan lokasi dan usia.

"""

user.info()

"""Hasil `user.info()` menunjukkan bahwa dataset berisi 300 entri dengan 3 kolom: `User_Id`, `Location`, dan `Age`. Semua kolom memiliki data lengkap (tidak ada missing value). `User_Id` dan `Age` bertipe numerik (`int64`), sementara `Location` bertipe teks (`object`). Dataset ini bersih dan siap digunakan untuk analisis atau pemodelan, terutama dalam sistem rekomendasi berbasis pengguna atau segmentasi berdasarkan lokasi dan usia.

"""

# Statistik unik
print("Jumlah user unik:", tourism_rating['User_Id'].nunique())
print("Jumlah tempat wisata unik:", tourism_rating['Place_Id'].nunique())

"""Tahap tersebut menghasilkan statistik jumlah entitas unik dalam dataset `tourism_rating`. Hasilnya menunjukkan bahwa terdapat 300 pengguna unik (`User_Id`) dan 437 tempat wisata unik(`Place_Id`) yang terlibat dalam proses pemberian rating. Ini mengindikasikan bahwa sistem rekomendasi memiliki cakupan data yang luas baik dari sisi pengguna maupun destinasi wisata, yang merupakan dasar penting untuk membangun model rekomendasi yang efektif.

## 2. Data Preprocessing

### Menggabungkan Semua Tempat (placeID Unik)
"""

# Menggabungkan seluruh placeID dari file tempat wisata
place_all = tourism['Place_Id'].unique()

# Mengurutkan dan menghapus duplikat
place_all = np.sort(np.unique(place_all))

print('Jumlah seluruh tempat wisata unik berdasarkan Place_Id:', len(place_all))

"""Tahap tersebut digunakan untuk memperoleh seluruh ID tempat wisata unik dari dataset tourism. Pertama, Place_Id diambil dan diubah menjadi array unik menggunakan np.unique(), lalu diurutkan dengan np.sort(). Hasil akhirnya menunjukkan bahwa terdapat 437 tempat wisata unik berdasarkan kolom Place_Id, yang sesuai dengan jumlah tempat wisata dalam dataset.

### Menggabungkan Semua User
"""

# Menggabungkan seluruh userID dari file user dan rating
user_all = np.concatenate((
    tourism_rating['User_Id'].unique(), # Changed rating to tourism_rating
    user['User_Id'].unique()
))

# Menghapus duplikat dan mengurutkan
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user unik:', len(user_all))

"""Pada tahap ini menggabungkan seluruh ID pengguna (User_Id) dari dua dataset: tourism_rating dan user. Setelah digabung, kode menggunakan np.unique() untuk menghapus duplikat, lalu mengurutkan hasilnya. Hasil akhirnya menunjukkan bahwa terdapat 300 pengguna unik secara keseluruhan.

### Melihat Jumlah Rating
"""

print("Jumlah data rating:", len(tourism_rating))
print("\nCek missing value:")
print(tourism_rating.isnull().sum())

"""Tahap ini menampilkan jumlah total data rating dalam dataset `tourism_rating`, yaitu 10.000 baris. Selain itu, pengecekan missing value menunjukkan bahwa tidak ada nilai yang hilang pada kolom `User_Id`, `Place_Id`, maupun `Place_Ratings`, sehingga data lengkap dan siap digunakan untuk analisis atau pemodelan.

### Gabungkan Rating dengan Nama Tempat
"""

# Ganti nama kolom agar sesuai
place = tourism.rename(columns={'Place_Id': 'placeID', 'Place_Name': 'name'})
rating = tourism_rating.rename(columns={'Place_Id': 'placeID', 'User_Id': 'userID'})

# Menggabungkan rating dengan nama tempat wisata
all_place_name = pd.merge(rating, place[['placeID', 'name', 'Category']], on='placeID', how='left')
print(all_place_name.head())

"""Pada tahap ini melakukan beberapa langkah penting untuk memudahkan analisis data. Pertama, kolom `Place_Id` dan `Place_Name` pada dataset `tourism` diganti namanya menjadi `placeID` dan `name` agar konsisten dengan dataset `tourism_rating` yang juga diubah kolom `Place_Id` dan `User_Id` menjadi `placeID` dan `userID`. Selanjutnya, kedua dataset tersebut digabung (`merge`) berdasarkan kolom `placeID` untuk menggabungkan data rating dengan informasi nama tempat wisata dan kategorinya. Hasilnya adalah tabel yang berisi ID pengguna, ID tempat, nilai rating, nama tempat wisata, dan kategori, sehingga memudahkan analisis dan rekomendasi berbasis konten dan rating.

### Gabungkan Data dengan Profil User
"""

# Gabungkan data user
user = user.rename(columns={'User_Id': 'userID'})

all_data = pd.merge(all_place_name, user, on='userID', how='left')
print(all_data.head())

"""Pada tahap ini menggabungkan data pengguna (user) dengan data rating dan informasi tempat wisata (all_place_name) berdasarkan kolom userID. Sebelumnya, kolom User_Id pada dataset user diubah menjadi userID agar konsisten. Hasil penggabungan (all_data) berisi informasi lengkap yang mencakup ID pengguna, ID tempat, rating, nama tempat, kategori, serta data demografis pengguna seperti lokasi dan usia. Data ini siap untuk analisis lebih lanjut, misalnya untuk personalisasi rekomendasi berdasarkan profil pengguna.

## 3. Data Preparation

### Cek Data Akhir & Missing Value
"""

print("Cek missing value setelah penggabungan:")
print(all_data.isnull().sum())

"""Tahapan ini memeriksa apakah terdapat nilai yang hilang (missing values) dalam dataset gabungan `all_data`. Hasilnya menunjukkan bahwa tidak ada missing value di semua kolom, sehingga data lengkap dan siap digunakan untuk analisis atau pemodelan tanpa perlu penanganan data kosong lebih lanjut.

"""

# Mengurutkan destinasi berdasarkan Place_Id kemudian memasukkannya ke dalam variabel fix_tourism
# Asumsi all_tourism_clean seharusnya adalah all_data atau hasil pembersihan dari all_data
all_tourism_clean = all_data

fix_tourism = all_tourism_clean.sort_values('placeID', ascending=True)
fix_tourism

"""Kode dan output ini mengurutkan dataset `all_tourism_clean` (yang merupakan data gabungan dan sudah dibersihkan) berdasarkan kolom `placeID` secara menaik, kemudian hasilnya disimpan ke variabel `fix_tourism`. Dengan pengurutan ini, data destinasi wisata tersusun rapi berdasarkan ID tempat, sehingga memudahkan analisis atau pemrosesan lanjutan yang membutuhkan data terorganisir menurut destinasi wisata.

"""

# Mengecek berapa jumlah fix_tourism
len(fix_tourism.placeID.unique())

"""Dapat dilihat dari outputnya yaitu menghasilkan 437 tempat wisata yang unik."""

fix_tourism.Category.unique()

"""Dapat dilihat tahapan ini menampilkan daftar kategori unik yang ada di dalam kolom category."""

# Langsung pakai all_wisata_clean dan urutkan
preparation = all_tourism_clean.sort_values('placeID', ascending=True)

# Tampilkan 5 data teratas
preparation.head()

"""Kode dan output berikut mengurutkan data all_tourism_clean berdasarkan kolom placeID secara menaik, kemudian menyimpannya dalam variabel preparation. Setelah itu, 5 baris data teratas ditampilkan untuk melihat contoh data yang sudah terurut. Data ini berisi informasi lengkap tentang pengguna, tempat wisata, rating, kategori, lokasi, dan usia pengguna."""

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('placeID')
preparation

"""Kode dan output ini menghapus baris duplikat berdasarkan kolom placeID di variabel preparation, sehingga setiap tempat wisata hanya muncul satu kali dalam data. Hasilnya adalah dataset yang berisi data unik untuk setiap tempat wisata, lengkap dengan informasi pengguna yang terakhir muncul untuk masing-masing tempat tersebut."""

# Mengonversi data series ‘Place_Id’ menjadi dalam bentuk list
tourism_id = preparation['placeID'].tolist()

# Mengonversi data series ‘Place_Name’ menjadi dalam bentuk list
tourism_name = preparation['name'].tolist() # Also update Place_Name to 'name' based on rename

# Mengonversi data series ‘Category’ menjadi dalam bentuk list
tourism_category = preparation['Category'].tolist()

print(len(tourism_id))
print(len(tourism_name))
print(len(tourism_category))

"""Pada tahap ini yaitu mengubah tiga kolom dari dataframe preparation—yaitu placeID, name, dan Category—menjadi list Python terpisah. Setiap list berisi 437 elemen yang merepresentasikan semua tempat wisata unik beserta nama dan kategorinya."""

# Membuat dataframe baru dari tourism_id, tourism_name, dan tourism_category
tourism_new = pd.DataFrame({
    'id': tourism_id,
    'place_name': tourism_name,
    'category': tourism_category
})

tourism_new

"""Tahap ini, membuat sebuah DataFrame baru bernama tourism_new yang berisi tiga kolom: id (ID tempat wisata), place_name (nama tempat wisata), dan category (kategori tempat wisata). DataFrame ini terdiri dari 437 baris yang merepresentasikan seluruh tempat wisata unik yang sudah diproses sebelumnya.

# 4. Model Development Content Based Filtering
"""

data = tourism_new
data.sample(5)

"""Menampilkan secara acak 5 baris sampel dari DataFrame tourism_new (disimpan dalam variabel data). Output menunjukkan contoh tempat wisata beserta ID dan kategorinya, seperti Curug Luhur Waterfall (Cagar Alam), Museum Geologi Bandung (Budaya), dan Pantai Baruna (Bahari). Ini berguna untuk melihat sekilas isi data secara acak.

### TF-IDF Vectorizer
"""

# Inisialisasi TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer() # Renamed the variable

# Melakukan perhitungan idf pada data kategori tempat wisata
tfidf_vectorizer.fit(tourism_new['category'])

# Mapping array dari fitur index integer ke nama fitur (kategori wisata)
tfidf_vectorizer.get_feature_names_out()

"""Pada tahap ini menggunakan TfidfVectorizer untuk mengubah data kategori tempat wisata menjadi representasi numerik berdasarkan frekuensi dan pentingnya kata (TF-IDF). Setelah dilakukan fitting pada kolom category, dihasilkan daftar fitur unik berupa kata-kata yang membentuk kategori, seperti 'budaya', 'taman', 'hiburan', dll. Fitur ini bisa digunakan untuk analisis teks atau pemodelan lebih lanjut."""

# Melakukan fit lalu transform ke dalam bentuk matriks TF-IDF berdasarkan kategori wisata
tfidf_matrix = tfidf_vectorizer.fit_transform(tourism_new['category']) # Use the new variable name

# Melihat ukuran matriks TF-IDF
tfidf_matrix.shape

"""Mengubah data kategori wisata dari tourism_new['category'] menjadi matriks TF-IDF menggunakan fit_transform. Matriks ini merepresentasikan 437 tempat wisata (baris) dan 10 kata fitur unik (kolom) yang dihasilkan sebelumnya. Jadi, ukuran matriks (437, 10) menunjukkan ada 437 dokumen (tempat wisata) dan 10 fitur kata unik kategori yang dipakai untuk analisis lebih lanjut."""

# Mengubah vektor TF-IDF ke dalam bentuk matriks dense
tfidf_dense = tfidf_matrix.todense()

# Menampilkan matriks TF-IDF dalam bentuk dense
tfidf_dense

"""Pada tahapan ini yaitu mengubah matriks TF-IDF yang sebelumnya dalam format sparse matrix menjadi matriks dense (penuh) menggunakan .todense(). Outputnya adalah matriks numerik lengkap yang menampilkan bobot TF-IDF setiap fitur kategori untuk setiap tempat wisata. Nilai-nilai di dalam matriks menunjukkan seberapa penting suatu kata (kategori) dalam deskripsi tiap tempat wisata, dengan angka 0 artinya kata tersebut tidak muncul pada kategori tersebut."""

# Membuat dataframe TF-IDF matrix
# Kolom = kategori wisata (fitur TF-IDF)
# Baris = nama tempat wisata

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer.get_feature_names_out(), # Use the new variable name
    index=tourism_new['place_name']
).sample(22, axis=1, replace=True).sample(10, axis=0)

"""Untuk tahapan ini  sebuah DataFrame dari matriks TF-IDF yang telah dihitung sebelumnya, di mana kolom-kolomnya merepresentasikan kategori wisata (fitur TF-IDF) dan baris-barisnya adalah nama-nama tempat wisata. Kemudian, kode tersebut mengambil sampel acak sebanyak 22 kolom dan 10 baris untuk menampilkan sebagian data secara acak, sehingga memudahkan dalam melihat representasi bobot kategori pada beberapa tempat wisata secara ringkas.

### Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity antar destinasi wisata
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Menghitung osine similarity antara semua destinasi wisata berdasarkan matriks TF-IDF kategori mereka. Hasilnya adalah sebuah matriks yang menunjukkan seberapa mirip setiap pasangan tempat wisata, dengan nilai 1 berarti identik dan nilai mendekati 0 berarti kurang mirip."""

# Membuat dataframe dari variabel cosine_sim
# Baris dan kolom diisi dengan nama destinasi
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['place_name'], columns=data['place_name'])

# Menampilkan ukuran matrix cosine similarity
print('Shape:', cosine_sim_df.shape)

# Melihat contoh similarity antar destinasi
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Kode dan output yang dihasilkan yaitu membuat dataframe dari matriks cosine similarity dengan baris dan kolom berupa nama destinasi wisata. Ukuran matriks adalah 437x437, yang berarti similarity dihitung antar semua 437 destinasi. Contoh yang ditampilkan memperlihatkan nilai similarity antar beberapa destinasi, di mana nilai 1 menunjukkan destinasi yang sangat mirip atau sama kategori, dan nilai 0 menunjukkan tidak mirip.

### Mendapatkan Rekomendasi
"""

def tourism_recommendations(nama_tempat, similarity_data=cosine_sim_df, items=data[['place_name', 'category']], k=5):
    """
    Rekomendasi Tempat Wisata berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_tempat : str
        Nama Tempat Wisata yang ingin direkomendasikan tempat serupa
    similarity_data : pd.DataFrame
        Matrix similarity cosine antar tempat wisata
    items : pd.DataFrame
        DataFrame yang berisi nama tempat dan kategori
    k : int
        Jumlah rekomendasi yang diberikan

    Return:
    ---
    DataFrame dengan k rekomendasi tempat wisata yang mirip
    """
    # Cek apakah nama_tempat ada di similarity_data
    if nama_tempat not in similarity_data.columns:
        return f"Tempat wisata '{nama_tempat}' tidak ditemukan."

    # Mengambil index dari nilai similarity tertinggi
    index = similarity_data.loc[:, nama_tempat].to_numpy().argpartition(range(-1, -k-1, -1))

    # Mengambil k+1 tempat wisata terdekat (termasuk dirinya sendiri)
    closest_names = similarity_data.columns[index[-1:-(k+2):-1]].tolist()

    # Menghapus nama tempat itu sendiri dari hasil rekomendasi
    closest_names = [name for name in closest_names if name != nama_tempat]

    # Ambil hanya k hasil
    closest_names = closest_names[:k]

    # Gabungkan dengan data asli untuk mengambil info kategorinya
    rekomendasi = items[items['place_name'].isin(closest_names)].copy()

    # Optional: urutkan sesuai urutan similarity (jika diperlukan)
    rekomendasi['similarity'] = rekomendasi['place_name'].map(
        lambda x: similarity_data.loc[x, nama_tempat]
    )

    return rekomendasi[['place_name', 'category']].reset_index(drop=True)

"""Fungsi `tourism_recommendations` memberikan rekomendasi tempat wisata yang mirip berdasarkan nama tempat yang dimasukkan. Fungsi ini menggunakan matriks cosine similarity untuk mencari destinasi dengan kemiripan tertinggi. Jika nama tempat tidak ditemukan, fungsi mengembalikan pesan error. Fungsi mengambil `k` destinasi terdekat (kecuali tempat itu sendiri), lalu mengembalikan dataframe berisi nama dan kategori tempat wisata yang direkomendasikan, lengkap dengan nilai similarity sebagai referensi kemiripan.

"""

data[data.place_name.eq('Kampung Wisata Taman Sari')]

"""Menghasilkan detail destinasi wisata bernama "Kampung Wisata Taman Sari" yang termasuk dalam kategori Taman Hiburan dan memiliki id 90."""

tourism_recommendations('Kampung Wisata Taman Sari')

"""Fungsi rekomendasi menghasilkan daftar 5 tempat wisata serupa dengan "Kampung Wisata Taman Sari", semuanya masuk kategori Taman Hiburan, sehingga memberikan pilihan destinasi hiburan lain yang mirip berdasarkan kategori.

## 5. Model Development dengan Collaborative Filtering
"""

# Membaca dataset
df = rating
df

"""Dataset `df` berisi data rating pengguna terhadap tempat wisata, dengan kolom `userID` (ID pengguna), `placeID` (ID tempat wisata), dan `Place_Ratings` (nilai rating yang diberikan). Data ini merekam preferensi 300 pengguna terhadap berbagai tempat wisata.

### Data Preparation
"""

# Mengubah user_id menjadi list tanpa duplikat
user_ids = df['userID'].unique().tolist()
print('List user_id:', user_ids)

# Melakukan encoding user_id ke angka
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('Encoded user_id:', user_to_user_encoded)

# Melakukan decoding angka kembali ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('Encoded angka ke user_id:', user_encoded_to_user)

"""Pada tahap ini mengubah `userID` dalam dataset menjadi representasi angka unik mulai dari 0 untuk memudahkan pemrosesan data. Pertama, kode mengambil daftar `userID` tanpa duplikat lalu membuat dictionary untuk meng-encode `userID` asli ke angka dan sebaliknya untuk decoding. Proses ini membantu dalam mengelola data user secara efisien dalam model rekomendasi.

"""

# Mengubah placeID menjadi list tanpa duplikat
place_ids = df['placeID'].unique().tolist()

# Melakukan encoding placeID ke angka
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}

# Melakukan decoding angka ke placeID
place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}

"""Kode ini mengubah kolom `placeID` menjadi daftar unik tanpa duplikat, lalu membuat dua dictionary untuk mengonversi `placeID` asli ke angka (encoding) dan sebaliknya dari angka ke `placeID` asli (decoding). Tujuannya agar data tempat wisata dapat diproses lebih mudah dan efisien dalam analisis atau model rekomendasi.

"""

# Mapping userID ke dataframe
df['user'] = df['userID'].map(user_to_user_encoded)

# Mapping placeID ke dataframe (dalam konteks pariwisata, bukan resto)
df['place'] = df['placeID'].map(place_to_place_encoded)

"""Kode ini menambahkan dua kolom baru ke dataframe `df`, yaitu `user` dan `place`. Kolom `user` berisi hasil pemetaan `userID` asli ke kode angka menggunakan dictionary `user_to_user_encoded`, dan kolom `place` berisi hasil pemetaan `placeID` asli ke kode angka menggunakan `place_to_place_encoded`. Ini memudahkan pemrosesan data untuk analisis atau pembuatan model rekomendasi.

"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah destinasi wisata
num_places = len(place_encoded_to_place)
print(num_places)

# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# Nilai minimum rating
min_rating = df['Place_Ratings'].min()

# Nilai maksimum rating
max_rating = df['Place_Ratings'].max()

print('Number of Users: {}, Number of Places: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_places, min_rating, max_rating
))

"""Kode dan ouput ini menghitung dan menampilkan beberapa informasi penting dari dataset rating wisata, yaitu jumlah total user unik (300), jumlah destinasi wisata unik (437), serta nilai rating minimum (1.0) dan maksimum (5.0) setelah mengonversi rating menjadi tipe data float. Informasi ini berguna untuk memahami cakupan data sebelum pemodelan.

### Membagi Data untuk Training dan Validasi
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Kode di atas ini mengacak urutan baris pada dataset menggunakan fungsi `sample` dengan parameter `frac=1` (artinya mengambil seluruh data) dan `random_state=42` agar hasil pengacakan bisa direproduksi. Setelah itu, dataframe `df` yang sudah teracak ditampilkan dengan kolom userID, placeID, rating, dan encoding user serta place. Pengacakan ini biasanya dilakukan sebelum membagi data untuk pelatihan dan pengujian agar distribusi data lebih merata."""

# Membuat variabel x untuk mencocokkan data user dan tempat menjadi satu value
x = df[['user', 'place']].values

# Membuat variabel y untuk membuat rating dari hasil
# Menggunakan 'Place_Ratings' karena itu nama kolom rating setelah rename
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data training dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print("x (user & destinasi):", x[:5])
print("y (rating dinormalisasi):", y[:5])

"""Tahap ini yaitu mempersiapkan data dengan menggabungkan kolom user dan destinasi wisata menjadi fitur input `x`, serta mengubah rating menjadi nilai yang dinormalisasi antara 0 hingga 1 sebagai target `y`. Selanjutnya, data dibagi menjadi 80% untuk pelatihan dan 20% untuk validasi, dan ditampilkan beberapa nilai pasangan user-destinasi beserta rating yang sudah dinormalisasi.

### Proses Training
"""

class RecommenderNet(tf.keras.Model):

    # Inisialisasi fungsi
    def __init__(self, num_users, num_places, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_places = num_places
        self.embedding_size = embedding_size

        # Embedding user
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )

        # Bias untuk user
        self.user_bias = layers.Embedding(num_users, 1)

        # Embedding tempat wisata
        self.place_embedding = layers.Embedding(
            num_places,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )

        # Bias untuk tempat wisata
        self.place_bias = layers.Embedding(num_places, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        place_vector = self.place_embedding(inputs[:, 1])
        place_bias = self.place_bias(inputs[:, 1])

        # Perkalian dot product
        dot_user_place = tf.tensordot(user_vector, place_vector, 2)

        # Menambahkan bias
        x = dot_user_place + user_bias + place_bias

        # Menggunakan sigmoid untuk output rating antara 0 - 1
        return tf.nn.sigmoid(x)

"""Kelas `RecommenderNet` adalah model rekomendasi berbasis embedding yang mengubah ID user dan tempat menjadi representasi vektor berdimensi rendah. Model ini membuat embedding untuk user dan tempat beserta bias masing-masing, lalu menghitung interaksi keduanya dengan dot product. Hasilnya dijumlahkan dengan bias dan diaktifkan menggunakan fungsi sigmoid untuk menghasilkan prediksi rating yang bernilai antara 0 sampai 1."""

# Inisialisasi model rekomendasi tempat wisata
model = RecommenderNet(num_users, num_places, 50)

# Compile model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model rekomendasi tempat wisata diinisialisasi dengan menggunakan kelas `RecommenderNet` yang memiliki 50 dimensi embedding untuk user dan tempat. Model kemudian dikompilasi dengan fungsi loss binary crossentropy, optimizer Adam dengan learning rate 0.001, serta metrik evaluasi root mean squared error (RMSE) untuk mengukur performa prediksi.

"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 50,
    validation_data = (x_val, y_val)
)

"""Model dilatih menggunakan data training dengan batch size 8 selama 50 epoch, sekaligus melakukan evaluasi pada data validasi untuk memantau performa selama proses training berlangsung. Dapat dilihat model berhasil dijalankan.

"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Grafik dan kode yang ditampilkan menunjukkan performa model rekomendasi berdasarkan nilai Root Mean Squared Error (RMSE) selama proses pelatihan. Pada grafik tersebut, garis biru mewakili RMSE untuk data pelatihan (train), sedangkan garis oranye untuk data validasi (test). Terlihat bahwa RMSE pada data pelatihan terus menurun seiring bertambahnya epoch, yang menunjukkan bahwa model semakin baik dalam mempelajari pola dari data pelatihan. Namun, RMSE pada data validasi justru meningkat setelah beberapa epoch, yang menandakan terjadinya overfitting—model terlalu fokus pada data pelatihan sehingga kehilangan kemampuan untuk menggeneralisasi ke data baru."""

# Mengambil sample user
user_id = df.userID.sample(1).iloc[0]
places_visited_by_user = df[df.userID == user_id]

# Tempat yang belum dikunjungi user
# Mengganti 'id' dengan 'placeID'
places_not_visited = fix_tourism[~fix_tourism['placeID'].isin(places_visited_by_user.placeID.values)]['placeID']
places_not_visited = list(
    set(places_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

places_not_visited = [[place_to_place_encoded.get(x)] for x in places_not_visited]
user_encoder = user_to_user_encoded.get(user_id)

user_place_array = np.hstack(
    ([[user_encoder]] * len(places_not_visited), places_not_visited)
)

"""Langkah ini dimulai dengan mengambil secara acak satu user dari data, lalu mengidentifikasi tempat-tempat wisata yang telah dikunjungi user tersebut. Selanjutnya, sistem mencari tempat-tempat yang belum dikunjungi user tersebut dari data `fix_tourism`, lalu mengonversinya ke dalam bentuk encoded sesuai dengan model. Data ini kemudian dikombinasikan dengan ID user yang telah diencoding untuk membentuk array input yang siap diprediksi oleh model rekomendasi.

"""

# Mengambil sample user
user_id = df.userID.sample(1).iloc[0]
places_visited_by_user = df[df.userID == user_id]

# Tempat yang belum dikunjungi user
# Mengganti 'id' dengan 'placeID'
# Corrected column name from 'id' to 'placeID' in fix_tourism
places_not_visited = fix_tourism[~fix_tourism['placeID'].isin(places_visited_by_user.placeID.values)]['placeID']
places_not_visited = list(
    set(places_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

# Ubah jadi input model
places_not_visited = [[place_to_place_encoded.get(x)] for x in places_not_visited]
user_encoder = user_to_user_encoded.get(user_id)

user_place_array = np.hstack(
    ([[user_encoder]] * len(places_not_visited), places_not_visited)
)

# Prediksi rating dari model
ratings = model.predict(user_place_array).flatten()

# Ambil top 10 rekomendasi dengan skor tertinggi
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(places_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for user:', user_id)
print('=' * 30)
print('Tempat wisata dengan rating tinggi dari user')
print('-' * 30)

top_places_user = (
    places_visited_by_user.sort_values(
        by='Place_Ratings',
        ascending=False
    )
    .head(5)
    .placeID.values
)

# Replaced tourism_df with tourism_new which contains 'id' column
tourism_new_rows = tourism_new[tourism_new['id'].isin(top_places_user)]
for row in tourism_new_rows.itertuples():
    print(row.place_name, ':', row.category)

print('-' * 30)
print('Top 10 rekomendasi tempat wisata')
print('-' * 30)

# Replaced tourism_df with tourism_new
recommended_places = tourism_new[tourism_new['id'].isin(recommended_place_ids)]
for row in recommended_places.itertuples():
    print(row.place_name, ':', row.category)

"""Proses ini menghasilkan rekomendasi tempat wisata untuk satu user yang dipilih secara acak. Sistem terlebih dahulu mengidentifikasi destinasi yang belum pernah dikunjungi oleh user, lalu memprediksi rating potensial untuk tempat-tempat tersebut menggunakan model. Dari hasil prediksi, dipilih 10 tempat dengan skor tertinggi sebagai rekomendasi. Selain itu, sistem juga menampilkan lima destinasi dengan rating tertinggi yang pernah dikunjungi user tersebut sebagai pembanding. Sistem merekomendasikan 10 tempat wisata terbaik untuk user 105 berdasarkan prediksi rating tertinggi dari model. Rekomendasi mencakup berbagai kategori seperti taman hiburan, budaya, bahari, cagar alam, dan tempat ikonik lainnya. Selain itu, ditampilkan pula 5 tempat wisata favorit user berdasarkan rating tertinggi yang pernah diberikannya, menunjukkan preferensi user terhadap taman hiburan dan tempat berbudaya.


"""